{"filter":false,"title":"app.py","tooltip":"/Parcial/app.py","undoManager":{"mark":16,"position":16,"stack":[[{"start":{"row":0,"column":0},"end":{"row":51,"column":0},"action":"insert","lines":["import requests","import boto3","from datetime import datetime","","# Inicializar cliente S3","s3_client = boto3.client('s3')","","# URL de las páginas que deseas descargar","URLs = {","    \"el_tiempo\": \"https://www.eltiempo.com/\",","    \"el_espectador\": \"https://cartelera.elespectador.com/\"","}","","# Nombre del bucket S3","S3_BUCKET = \"nombre-del-bucket\"","","def download_page(url):","    \"\"\"Descargar la página web y retornar el contenido HTML\"\"\"","    response = requests.get(url)","    if response.status_code == 200:","        return response.text","    else:","        raise Exception(f\"Error al descargar la página: {url}\")","","def save_to_s3(content):","    \"\"\"Guardar el contenido descargado en un archivo S3\"\"\"","    # Crear la ruta con fecha","    date_str = datetime.now().strftime(\"%Y-%m-%d\")","    file_name = f\"headlines/raw/contenido-{date_str}.html\"","    ","    # Guardar el contenido en S3","    s3_client.put_object(","        Bucket=S3_BUCKET,","        Key=file_name,","        Body=content,","        ContentType=\"text/html\"","    )","    print(f\"Archivo guardado en S3: {file_name}\")","","def lambda_handler(event, context):","    \"\"\"Manejador Lambda principal\"\"\"","    for page_name, url in URLs.items():","        print(f\"Descargando la página de {page_name}...\")","        try:","            # Descargar el contenido de la página","            content = download_page(url)","            ","            # Guardar el contenido en S3","            save_to_s3(content)","        except Exception as e:","            print(f\"Error al procesar la página {page_name}: {e}\")",""],"id":21}],[{"start":{"row":50,"column":66},"end":{"row":51,"column":0},"action":"remove","lines":["",""],"id":22}],[{"start":{"row":32,"column":23},"end":{"row":32,"column":24},"action":"remove","lines":["T"],"id":23},{"start":{"row":32,"column":22},"end":{"row":32,"column":23},"action":"remove","lines":["E"]},{"start":{"row":32,"column":21},"end":{"row":32,"column":22},"action":"remove","lines":["K"]},{"start":{"row":32,"column":20},"end":{"row":32,"column":21},"action":"remove","lines":["C"]},{"start":{"row":32,"column":19},"end":{"row":32,"column":20},"action":"remove","lines":["U"]},{"start":{"row":32,"column":18},"end":{"row":32,"column":19},"action":"remove","lines":["B"]},{"start":{"row":32,"column":17},"end":{"row":32,"column":18},"action":"remove","lines":["_"]},{"start":{"row":32,"column":16},"end":{"row":32,"column":17},"action":"remove","lines":["3"]},{"start":{"row":32,"column":15},"end":{"row":32,"column":16},"action":"remove","lines":["S"]}],[{"start":{"row":32,"column":15},"end":{"row":32,"column":17},"action":"insert","lines":["\"\""],"id":24}],[{"start":{"row":32,"column":16},"end":{"row":32,"column":28},"action":"insert","lines":["zappaparcial"],"id":25}],[{"start":{"row":32,"column":28},"end":{"row":32,"column":29},"action":"remove","lines":["\""],"id":26},{"start":{"row":32,"column":27},"end":{"row":32,"column":28},"action":"remove","lines":["l"]},{"start":{"row":32,"column":26},"end":{"row":32,"column":27},"action":"remove","lines":["a"]},{"start":{"row":32,"column":25},"end":{"row":32,"column":26},"action":"remove","lines":["i"]},{"start":{"row":32,"column":24},"end":{"row":32,"column":25},"action":"remove","lines":["c"]},{"start":{"row":32,"column":23},"end":{"row":32,"column":24},"action":"remove","lines":["r"]},{"start":{"row":32,"column":22},"end":{"row":32,"column":23},"action":"remove","lines":["a"]},{"start":{"row":32,"column":21},"end":{"row":32,"column":22},"action":"remove","lines":["p"]},{"start":{"row":32,"column":20},"end":{"row":32,"column":21},"action":"remove","lines":["a"]},{"start":{"row":32,"column":19},"end":{"row":32,"column":20},"action":"remove","lines":["p"]},{"start":{"row":32,"column":18},"end":{"row":32,"column":19},"action":"remove","lines":["p"]},{"start":{"row":32,"column":17},"end":{"row":32,"column":18},"action":"remove","lines":["a"]},{"start":{"row":32,"column":16},"end":{"row":32,"column":17},"action":"remove","lines":["z"]},{"start":{"row":32,"column":15},"end":{"row":32,"column":16},"action":"remove","lines":["\""]}],[{"start":{"row":32,"column":15},"end":{"row":32,"column":16},"action":"insert","lines":["S"],"id":27},{"start":{"row":32,"column":16},"end":{"row":32,"column":17},"action":"insert","lines":["3"]},{"start":{"row":32,"column":17},"end":{"row":32,"column":18},"action":"insert","lines":["_"]}],[{"start":{"row":32,"column":15},"end":{"row":32,"column":18},"action":"remove","lines":["S3_"],"id":28},{"start":{"row":32,"column":15},"end":{"row":32,"column":24},"action":"insert","lines":["S3_BUCKET"]}],[{"start":{"row":0,"column":0},"end":{"row":50,"column":66},"action":"remove","lines":["import requests","import boto3","from datetime import datetime","","# Inicializar cliente S3","s3_client = boto3.client('s3')","","# URL de las páginas que deseas descargar","URLs = {","    \"el_tiempo\": \"https://www.eltiempo.com/\",","    \"el_espectador\": \"https://cartelera.elespectador.com/\"","}","","# Nombre del bucket S3","S3_BUCKET = \"nombre-del-bucket\"","","def download_page(url):","    \"\"\"Descargar la página web y retornar el contenido HTML\"\"\"","    response = requests.get(url)","    if response.status_code == 200:","        return response.text","    else:","        raise Exception(f\"Error al descargar la página: {url}\")","","def save_to_s3(content):","    \"\"\"Guardar el contenido descargado en un archivo S3\"\"\"","    # Crear la ruta con fecha","    date_str = datetime.now().strftime(\"%Y-%m-%d\")","    file_name = f\"headlines/raw/contenido-{date_str}.html\"","    ","    # Guardar el contenido en S3","    s3_client.put_object(","        Bucket=S3_BUCKET,","        Key=file_name,","        Body=content,","        ContentType=\"text/html\"","    )","    print(f\"Archivo guardado en S3: {file_name}\")","","def lambda_handler(event, context):","    \"\"\"Manejador Lambda principal\"\"\"","    for page_name, url in URLs.items():","        print(f\"Descargando la página de {page_name}...\")","        try:","            # Descargar el contenido de la página","            content = download_page(url)","            ","            # Guardar el contenido en S3","            save_to_s3(content)","        except Exception as e:","            print(f\"Error al procesar la página {page_name}: {e}\")"],"id":29},{"start":{"row":0,"column":0},"end":{"row":104,"column":67},"action":"insert","lines":["import requests","import boto3","from datetime import datetime","from bs4 import BeautifulSoup","import csv","import os","","# Crear un cliente de S3","s3_client = boto3.client('s3')","","# Primera función Lambda: Descarga el contenido y lo sube a S3","def f(event, context):","    bucket_name = \"parcial3-lambda1\"  # Bucket específico para esta función","    base_path = \"headlines/raw\"","","    urls = {","        \"el_tiempo\": \"https://www.eltiempo.com/\",","        \"el_espectador\": \"https://www.elespectador.com/\",","        \"publimetro\": \"https://www.publimetro.co/\"","    }","","    today = datetime.utcnow().strftime(\"%Y-%m-%d\")","","    for source, url in urls.items():","        try:","            response = requests.get(url)","            response.raise_for_status()","            content = response.text","","            filename = f\"{base_path}/{source}-contenido-{today}.html\"","","            s3_client.put_object(","                Bucket=bucket_name,","                Key=filename,","                Body=content,","                ContentType=\"text/html\"","            )","            print(f\"Contenido de {source} subido correctamente a {filename}\")","        except Exception as e:","            print(f\"Error al procesar {source}: {e}\")","","","# Segunda función Lambda: Procesa los datos de S3 y genera un CSV","","def process_data(event, context):","    bucket_name = \"parcial3-lambda1\"  # Bucket donde están los datos RAW","    processed_bucket_name = \"parcial3-lambda2\"  # Bucket destino para el CSV","    final_path = \"headlines/final\"","","    for record in event['Records']:","        key = record['s3']['object']['key']","        source = key.split('/')[-1].split('-')[0]  # Extraer el nombre del periódico","","        # Descargar el archivo desde S3","        obj = s3_client.get_object(Bucket=bucket_name, Key=key)","        html_content = obj['Body'].read().decode('utf-8')","","        # Procesar el HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, 'html.parser')","","        headlines = []","        for article in soup.find_all('article'):","            title = article.find('h2') or article.find('h3')","            link = article.find('a')","            if title and link:","                headlines.append({","                    \"category\": source,","                    \"headline\": title.get_text(strip=True),","                    \"link\": link['href']","                })","","        # Generar un archivo CSV","        today = datetime.utcnow()","        year, month, day = today.strftime(\"%Y\"), today.strftime(\"%m\"), today.strftime(\"%d\")","        csv_filename = f\"{final_path}/periodico={source}/year={year}/month={month}/day={day}/headlines.csv\"","","        # Guardar los datos en el archivo CSV","        csv_content = \"category,headline,link\\n\"","        csv_content += \"\\n\".join([f\"{h['category']},{h['headline']},{h['link']}\" for h in headlines])","","        # Subir el archivo CSV a S3","        s3_client.put_object(","            Bucket=processed_bucket_name,","            Key=csv_filename,","            Body=csv_content,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo CSV subido correctamente a {csv_filename}\")","        ","","# Crear un cliente de Glue","glue_client = boto3.client('glue')","","def run_glue_crawler(event, context):","    # Nombre del crawler en Glue","    crawler_name = \"mi_crawler\"","","    try:","        # Ejecutar el crawler","        response = glue_client.start_crawler(Name=crawler_name)","        print(f\"Crawler '{crawler_name}' iniciado correctamente: {response}\")","    except glue_client.exceptions.CrawlerRunningException:","        print(f\"El crawler '{crawler_name}' ya está en ejecución.\")","    except Exception as e:","        print(f\"Error al iniciar el crawler '{crawler_name}': {e}\")"]}],[{"start":{"row":12,"column":26},"end":{"row":12,"column":27},"action":"remove","lines":["3"],"id":30}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"remove","lines":["3"],"id":31}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"insert","lines":["2"],"id":32}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"remove","lines":["2"],"id":33}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"insert","lines":["3"],"id":34}],[{"start":{"row":45,"column":27},"end":{"row":45,"column":28},"action":"remove","lines":["-"],"id":35},{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"remove","lines":["3"]}],[{"start":{"row":45,"column":26},"end":{"row":45,"column":27},"action":"insert","lines":["-"],"id":36}],[{"start":{"row":46,"column":36},"end":{"row":46,"column":37},"action":"remove","lines":["3"],"id":37}]]},"ace":{"folds":[],"scrolltop":769,"scrollleft":0,"selection":{"start":{"row":92,"column":0},"end":{"row":92,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":53,"state":"start","mode":"ace/mode/python"}},"timestamp":1732209708692,"hash":"fda31113596163e869d2a5bce0f84d4ae3881d08"}